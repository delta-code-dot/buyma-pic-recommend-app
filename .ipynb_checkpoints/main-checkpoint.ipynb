{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5b5b8a-971d-4f80-8529-ccccaef5b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from stqdm import stqdm\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model, layers\n",
    "from annoy import AnnoyIndex\n",
    "import glob\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8f45f047-a22a-43e9-8a65-20211db02704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd23203e-145c-4298-a6f1-8d5e9b1b83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    res=requests.get(url)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01beac12-1df7-46a4-be50-650f8a173550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages(url):\n",
    "    res=get_html(url)\n",
    "    soup_n = bs(res.content,\"html.parser\")\n",
    "    nums = soup_n.find_all(class_=\"paging\")[0]\n",
    "    nums = nums.find_all(\"a\")[-1].get('href')\n",
    "    nums = nums.split(\"_\")[-1].replace('/', '')\n",
    "    page = int(nums)\n",
    "    \n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "180dc320-9bed-46db-993c-56d1819480b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def details(item):\n",
    "    item = item.find_all(class_=\"product_img js-ecommerce-action\")\n",
    "    return {\n",
    "        \"name\": item[0].get(\"syo_name\"),\n",
    "        \"pic\": item[0].img.get('src'),\n",
    "        \"URL\":\"https://www.buyma.com/item/\"+str(item[0].get(\"syo_id\"))+\"/\"\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "07641cf7-ce99-4ca3-b4ae-c71fdc06055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_maker(items_list):\n",
    "    li = []\n",
    "    \n",
    "    for item in items_list:\n",
    "        try:\n",
    "            li.append(details(item))\n",
    "        \n",
    "        except:\n",
    "            del item\n",
    "    \n",
    "    df = pd.DataFrame(li)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0fba3d0-84b4-421e-b2e6-2412aa350b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url):\n",
    "    items_list=[]\n",
    "    n=pages(url)\n",
    "    \n",
    "    urls_list=[]\n",
    "    \n",
    "    for i in tqdm(range(1,n+1)):\n",
    "        if i==1:\n",
    "            urls_list.append(url)\n",
    "        \n",
    "        else:\n",
    "            url= \"https://www.buyma.com/r/-C1002/\"+text+\"_\"+str(i)+\"/\"\n",
    "            urls_list.append(url)\n",
    "    \n",
    "    items_list=[]\n",
    "    for url in tqdm(urls_list):\n",
    "        res=get_html(url)\n",
    "        soup = bs(res.content,\"html.parser\")\n",
    "        items = soup.find_all(class_= \"product_lists\")[0]\n",
    "        items = items.find_all(class_=\"product js-psnlz-item\")\n",
    "        items_list+=[item for item in items]\n",
    "    \n",
    "    return items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6bd14-9b2a-4be3-a17f-0ffc942c45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, file_path):\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c2f30-f89d-4b34-9f07-65077a42df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scr(title):\n",
    "    \n",
    "    url = \"https://www.buyma.com/r/-C1002/\"+text+\"/\"\n",
    "    base_dir = \"./\"\n",
    "    thumb_dir = os.path.join(base_dir, \"pics_file\")\n",
    "    \n",
    "    item_url=scraper(url)\n",
    "    df = df_maker(item_url)\n",
    "    \n",
    "    base_model = VGG16(weights=\"imagenet\")\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer(\"fc2\").output)\n",
    "\n",
    "    for i in stqdm(range(len(df))):\n",
    "        url=df[\"pic\"][i]\n",
    "        file_name = \"{}.jpg\".format(i)\n",
    "        image_path = os.path.join(thumb_dir, file_name)\n",
    "        download_image(url=url, file_path=image_path)\n",
    "\n",
    "    if os.path.exists(\"./pics_file/target 2.jpg\"):\n",
    "        os.remove(\"./pics_file/target 2.jpg\")\n",
    "    \n",
    "    \n",
    "    dim = 4096\n",
    "    annoy_model = AnnoyIndex(dim)\n",
    "    numimg= 0\n",
    "    glob_dir = os.path.join(thumb_dir, \"*.jpg\")\n",
    "    \n",
    "    \n",
    "    files = glob.glob(glob_dir)\n",
    "    files = sorted(files, key=natural_keys)\n",
    "    \n",
    "    for file in stqdm(files):\n",
    "        img_path = file\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        fc2_features = model.predict(x,verbose=0)\n",
    "        annoy_model.add_item(numimg, fc2_features[0])\n",
    "        numimg += 1\n",
    "    \n",
    "    \n",
    "    annoy_model.build(numimg)\n",
    "    save_path = os.path.join(base_dir, \"result.ann\")\n",
    "    annoy_model.save(save_path)\n",
    "    annoy_model.unload()\n",
    "    trained_model = AnnoyIndex(4096)\n",
    "    trained_model.load(\"./result.ann\")\n",
    "    items = trained_model.get_nns_by_item(len(df), 7, search_k=-1, include_distances=False)\n",
    "\n",
    "    return df, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8db1a0-d9f2-41c7-bd88-7fb3c25e22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.title('buyma画像検索アプリ')\n",
    "    \n",
    "    #保存先の作成\n",
    "    dir = './pics_file'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "\n",
    "    #アップロードされた画像を保存先へ移動\n",
    "    uploaded_file=st.file_uploader(\"画像をアップロード\")\n",
    "\n",
    "    Image.open(uploaded_file).convert('RGB').save('target.jpg')\n",
    "    new_path = shutil.move('./target.jpg', './pics_file')\n",
    "\n",
    "    #検索名の入力\n",
    "    with st.form('text_form'):\n",
    "            search_text = st.text_input('商品名を入力')\n",
    "            button = st.form_submit_button('Search Image')\n",
    "\n",
    "    #スクレピングと類似画像検索の実行\n",
    "    df, items = scr(search_text)\n",
    "\n",
    "    #パス\n",
    "    base_dir = \"./\"\n",
    "    thumb_dir = os.path.join(base_dir, \"pics_file\")\n",
    "\n",
    "    #画像の表示\n",
    "    glob_target = os.path.join(thumb_dir, \"target.jpg\")\n",
    "    image_target = Image.open(glob_target )\n",
    "    st.image(image_target, caption='対象画像',width = 128)\n",
    "\n",
    "\n",
    "    for i in range(6):\n",
    "        glob_n = os.path.join(thumb_dir, f\"{int(items[i+1])}.jpg\")\n",
    "        img_n = Image.open(glob_n)\n",
    "        st.image(img_n, caption=f'レコメンド商品NO{i+1}',width = 128)\n",
    "        st.caption(df[\"URL\"][int(items[i+1])])\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
